# -*- coding: utf-8 -*-
"""
This file provides implementation of the MLExecutorAgent.
"""

import base64
import json
import pickle
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List

from agents.ml_agent.evocoder import (
    EvoCoder,
    EvoCoderConfig,
    EvoCoderEvaluatorConfig,
    STAGE_EVALUATORS,
    STAGE_PROVIDERS,
    Stage,
    TaskConfig,
)
from agents.ml_agent.utils import utils
from loongflow.agentsdk.logger import get_logger
from loongflow.agentsdk.message import ContentElement, Message, MimeType, Role
from loongflow.framework.pes import Worker
from loongflow.framework.pes.context import Context, LLMConfig, Workspace
from loongflow.framework.pes.database import EvolveDatabase
from loongflow.framework.pes.evaluator import EvaluationResult, Evaluator

logger = get_logger(__name__)


@dataclass
class MLExecutorAgentConfig:
    """Configuration for the ML Executor Agent"""

    llm_config: LLMConfig
    react_max_steps: int = 10
    evo_coder_timeout: int = 7200


@dataclass
class ExecutionContext:
    """Holds information."""

    parent_info_file_path: str
    parent_info: Dict[str, Any]
    eda_info_file_path: str
    eda_analysis: str
    eda_code: str
    best_plan_file_path: str
    best_plan: dict[str, str]
    assemble_models: dict[str, str] = field(default_factory=dict)
    assemble_plan: str = ""


@dataclass
class CoderResult:
    """Holds information about the EvoCoder."""

    name: str = ""
    code: str = ""
    artifacts: dict[str, Any] = field(default_factory=dict)


class MLExecutorAgent(Worker):
    """
    Orchestrates the execution of a machine learning pipeline based on plans
    generated by the MLExecutor. It manages code generation via EvoCoder, reuses
    existing code, executes the final pipeline, and evaluates the results.
    """

    STAGE_ORDER: List[Stage] = [
        Stage.LOAD_DATA,
        Stage.GET_SPLITTER,
        Stage.PREPROCESS,
        Stage.TRAIN_AND_PREDICT,
        Stage.ENSEMBLE,
        Stage.WORKFLOW,
    ]

    def __init__(self, config: Any, evaluator: Evaluator, db: EvolveDatabase):
        super().__init__()
        self.config = (
            config
            if isinstance(config, MLExecutorAgentConfig)
            else MLExecutorAgentConfig(**config)
        )
        self.evaluator = evaluator
        self.db = db

    async def run(self, context: Context, message: Message) -> Message:
        """
        The main entry point for the ML_Executor.

        Args:
            context: A context object.
            message: The input message from the MLExecutor

        Returns:
            A message containing the execution result, including score and artifacts.
        """
        logger.info("ML_Executor started.")
        try:
            # 1. Load all necessary inputs from files.
            execution_ctx = self._load_execution_ctx(message)

            # 2. Prepare code for all stages, either by generating or reusing.
            solutions = await self._execute_pipeline(context, execution_ctx)
            logger.info("All pipeline stage codes are generated.")

            # save code
            best_code_path = utils.get_ml_executor_best_code_path(context)
            for result in solutions.values():
                best_code_path.joinpath(f"{result.name}.py").write_text(
                    result.code, encoding="utf-8"
                )

            # 3. Evaluate the submission file to get a score.
            evaluation = await self._evaluate(
                context,
                best_code_path,
                solutions.get(Stage.WORKFLOW, CoderResult()).artifacts,
            )

            evaluation.metrics["model_metrics"] = {
                "prediction_stats": solutions.get(Stage.WORKFLOW, CoderResult()).artifacts.get("prediction_stats"),
            }

            logger.info(f"evaluation successful. Final score: {evaluation.score}")

            best_evaluation_path = Workspace.get_executor_best_evaluation_path(context)

            Path(best_evaluation_path).write_text(evaluation.to_json())

            # 4. Return a success message with the results.
            return Message.from_media(
                sender="MLExecutor",
                role=Role.USER,
                mime_type=MimeType.APPLICATION_JSON,
                data={
                    "eda_info_file_path": execution_ctx.eda_info_file_path,
                    "best_plan_file_path": execution_ctx.best_plan_file_path,
                    "parent_info_file_path": execution_ctx.parent_info_file_path,
                    "best_solution_file_path": str(best_code_path),
                    "best_evaluation_file_path": best_evaluation_path,
                },
            )
        except Exception as e:
            logger.error(f"An error occurred during MLExecutor execution: {e}.")
            raise e

    def _load_execution_ctx(self, message: Message) -> ExecutionContext:
        """Loads plan, EDA report, and parent info from file paths in the message."""
        logger.info("Loading planner outputs.")

        content = message.get_elements(ContentElement)
        if (
                not content
                or len(content) == 0
                or not content[0].data
                or not isinstance(content[0].data, dict)
        ):
            raise ValueError(f"Missing content element data.")
        data = content[0].data

        try:
            with open(data.get("eda_info_file_path"), "r", encoding="utf-8") as f:
                eda_analysis = f.read()
        except Exception as e:
            logger.error(f"Failed to read EDA info file, error: {e}")
            eda_analysis = ""

        try:
            with open(data.get("eda_code_file_path"), "r", encoding="utf-8") as f:
                eda_code = f.read()
        except Exception as e:
            logger.error(f"Failed to read EDA code file, error: {e}")
            eda_code = ""

        try:
            with open(data.get("parent_info_file_path"), "r", encoding="utf-8") as f:
                parent_info = json.load(f)
        except Exception as e:
            logger.error(f"Failed to read parent info file, error: {e}")
            parent_info = {}

        try:
            with open(data.get("best_plan_file_path"), "r", encoding="utf-8") as f:
                best_plan = json.load(f)
        except Exception as e:
            logger.error(f"Failed to read best plan info file, error: {e}")
            best_plan = {}

        try:
            with open(data.get("model_assemble_file_path"), "r", encoding="utf-8") as f:
                assemble_info = json.load(f)
        except Exception as e:
            logger.error(f"Failed to read model assemble info file, error: {e}")
            assemble_info = {}

        ctx = ExecutionContext(
            parent_info_file_path=data.get("parent_info_file_path"),
            parent_info=parent_info,
            eda_info_file_path=data.get("eda_info_file_path"),
            eda_analysis=eda_analysis,
            eda_code=eda_code,
            best_plan_file_path=data.get("best_plan_file_path"),
            best_plan=best_plan,
        )

        if not assemble_info:
            return ctx

        # extract all assemble data
        solutions = self.db.get_solutions(assemble_info.get("solution_ids", []))
        assemble_models = {}
        for solution in solutions:
            if sol := solution.get("solution"):
                if solution.get("solution_id") == parent_info.get("solution_id"):
                    # we should ignore same solution id
                    continue
                code = json.loads(sol).get(Stage.TRAIN_AND_PREDICT.value)
                assemble_models[solution.get("solution_id")] = code

        return ExecutionContext(
            parent_info_file_path=data.get("parent_info_file_path"),
            parent_info=parent_info,
            eda_info_file_path=data.get("eda_info_file_path"),
            eda_analysis=eda_analysis,
            eda_code=eda_code,
            best_plan_file_path=data.get("best_plan_file_path"),
            best_plan=best_plan,
            assemble_models=assemble_models,
            assemble_plan=assemble_info.get("assemble_plan"),
        )

    async def _execute_pipeline(
        self,
        context: Context,
        execution_ctx: ExecutionContext,
    ) -> dict[Stage, CoderResult]:
        """
        Iterates through all stages, generating or reusing code as needed.
        """

        dep = {
            "eda": execution_ctx.eda_code,
        }
        results = {}
        try:
            parent_codes = json.loads(execution_ctx.parent_info.get("solution", "{}"))
        except Exception as e:
            logger.error(f"Failed to parse parent code, error: {e}")
            parent_codes = {}

        for stage in self.STAGE_ORDER:
            # since any stage could change signature of the method, such as return type changed from np.ndarray to
            # torch.Tensor, so every stage needs to rerun
            plan = execution_ctx.best_plan.get(stage.value, "")
            logger.info(f"{stage} generate plan instruction: {plan}")

            parent_code = parent_codes.get(stage.value, "")

            coder_result = await self._run_coder(
                context,
                stage,
                TaskConfig(
                    task_description=context.task,
                    task_data_path=context.metadata.get("task_data_path"),
                    eda_analysis=execution_ctx.eda_analysis,
                    plan=plan,
                    parent_code=parent_code,
                    code_deps=dep,
                    workspace_path=str(utils.get_ml_executor_output_path(context)),
                    gpu_available=context.metadata.get("gpu_available"),
                    gpu_count=context.metadata.get("gpu_count"),
                    hardware_info=context.metadata.get("hardware_info"),
                    task_dir_structure=context.metadata.get("task_dir_structure"),
                ),
            )

            dep[stage.value] = coder_result.code
            results[stage] = coder_result

        return results

    async def _run_coder(
        self,
        context: Context,
        stage: Stage,
        task_config: TaskConfig,
    ) -> CoderResult:

        evaluator = STAGE_EVALUATORS[stage](
            EvoCoderEvaluatorConfig(
                workspace_path=str(
                    utils.get_evocoder_evaluate_path(context, stage.value)
                ),
                timeout=self.config.evo_coder_timeout,
            )
        )

        coder = EvoCoder(
            config=EvoCoderConfig(
                llm_config=self.config.llm_config,
                context_provider=STAGE_PROVIDERS[stage](),
                evaluator=evaluator,
            )
        )

        try:
            response_message = await coder.run(
                message=Message.from_media(
                    sender="MLExecutor",
                    mime_type=MimeType.APPLICATION_JSON,
                    role=Role.USER,
                    data=task_config.to_dict(),
                )
            )
        finally:
            evaluator.interrupt()

        content = response_message.get_elements(ContentElement)
        if not content or len(content) == 0:
            raise RuntimeError(f"{stage} code generate empty")
        if not isinstance(content[0].data, dict):
            raise RuntimeError(f"{stage} code generate error")

        code = content[0].data.get("best_code")
        if not code:
            raise RuntimeError(f"{stage} code generate not found")
        artifacts = content[0].metadata.get("artifacts", {}).get(stage.value, {})
        return CoderResult(
            name=stage.value,
            code=code,
            artifacts=artifacts,
        )

    async def _evaluate(
        self, context: Context, code_path: Path, artifacts: dict[str, Any]
    ) -> EvaluationResult:
        """
        Evaluates the generated code or file.
        """

        data = {
            "task_data_path": context.metadata.get("task_data_path"),
            "best_code_path": str(code_path),
            "artifacts": artifacts,
        }
        pickled_data = pickle.dumps(data)
        encoded_data = base64.b64encode(pickled_data).decode("ascii")
        all_codes = f"""
import pickle
import base64
ML_AGENT_RESULT = pickle.loads(base64.b64decode('{encoded_data}'))
"""
        return await self.evaluator.evaluate(Message.from_text(data=f"{all_codes}"))